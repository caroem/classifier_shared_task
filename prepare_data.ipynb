{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import spacy\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spacy...\n",
      "...done\n"
     ]
    }
   ],
   "source": [
    "class Embedder(object):\n",
    "    def __init__(self, max_length=100):\n",
    "        self.max_length = max_length\n",
    "        print(\"Loading spacy...\")\n",
    "        self.nlp = spacy.load('en')\n",
    "        print(\"...done\")\n",
    "\n",
    "    def embed(self, text):\n",
    "        return self._pad(self._vectors(text))\n",
    "\n",
    "    def shape(self):\n",
    "        return (self.max_length, 300)\n",
    "\n",
    "    def _vectors(self, text):\n",
    "        doc = self.nlp(text)\n",
    "        vectors = []\n",
    "        for token in doc:\n",
    "            vectors.append(token.vector)\n",
    "        return vectors\n",
    "\n",
    "    def _pad(self, vectors):\n",
    "        vector_dim = len(vectors[0])\n",
    "        sequence = np.zeros((self.max_length, vector_dim))\n",
    "        for i, vector in enumerate(vectors):\n",
    "            if i == self.max_length:\n",
    "                break\n",
    "            sequence[i] = vector\n",
    "        return sequence\n",
    "\n",
    "class Predictor(object):\n",
    "    def __init__(self, embedder, model_path, intent_names_path):\n",
    "        self.model = load_model(model_path)\n",
    "        self.intent_names = pickle.load(open(intent_names_path, \"rb\"))\n",
    "        self.embedder = embedder\n",
    "\n",
    "    def predict(self, text):\n",
    "        proba = self._predict_proba(text)\n",
    "        return self.intent_names[np.argmax(proba)]\n",
    "\n",
    "    def _predict_proba(self, text):\n",
    "        embedding = self.embedder.embed(text)\n",
    "        return self.model.predict(np.array([embedding]))\n",
    "\n",
    "def predict(model, text):\n",
    "    embedding = embedder.embed(text)\n",
    "    return model.predict(np.array([embedding]))\n",
    "\n",
    "\n",
    "def translate(prediction, intent_names):\n",
    "    return intent_names[np.argmax(prediction)]\n",
    "\n",
    "\n",
    "def suggest(text):\n",
    "    prediction = predict(loaded_model, text)\n",
    "    return translate(prediction, loaded_intent_names)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(data_dir, limit=0):\n",
    "    examples = []\n",
    "    intent_names = {}\n",
    "    with open(data_dir + '/01.json') as data_file:\n",
    "        data = json.load(data_file)\n",
    "    for i, intent in enumerate(data):\n",
    "        intent_names[i] = intent[\"prompt\"]\n",
    "        for message in intent[\"response\"]:\n",
    "            examples.append((message, i))\n",
    "    np.random.shuffle(examples)\n",
    "    if limit >= 1:\n",
    "        examples = examples[:limit]\n",
    "    messages, intents = zip(*examples)\n",
    "    return examples, intent_names\n",
    "\n",
    "def dummy_encode(array, num_classes=None):\n",
    "    array = np.array(array)\n",
    "    if num_classes is None:\n",
    "        num_classes = max(array) + 1\n",
    "    result = np.zeros((len(array), num_classes))\n",
    "    result[np.arange(len(array)), array] = 1\n",
    "    return result\n",
    "\n",
    "def create_dataset(type):\n",
    "    if type == 'train':\n",
    "        data_dir = 'data/train'\n",
    "    elif type == 'dev':\n",
    "        data_dir = 'data/dev'\n",
    "    examples, intent_names = load_data(data_dir)\n",
    "    X = []\n",
    "    y = []\n",
    "    for example in examples:\n",
    "        message, intent = example[0], example[1]\n",
    "        X.append(embedder.embed(message))\n",
    "        y.append(intent)\n",
    "    return np.array(X), dummy_encode(np.array(y)), intent_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, intent_names_train = create_dataset('train')\n",
    "X_dev, y_dev, intent_names_dev = create_dataset('dev')\n",
    "X, y, intent_names = X_train, y_train, intent_names_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    sequences = Input(shape=input_shape)\n",
    "    x = Conv1D(400, 5, activation='relu')(sequences)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Conv1D(400, 3, activation='relu')(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(400, activation='relu')(x)\n",
    "    preds = Dense(len(intent_names), activation='softmax')(x)\n",
    "    model = Model(input=sequences, output=preds)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "def save_model(model, model_name):\n",
    "    model.save('output/' + model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(intent_names, open(\"output/intent_names.p\", \"wb\"))\n",
    "loaded_intent_names = pickle.load(open(\"output/intent_names.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26408 samples, validate on 8794 samples\n",
      "Epoch 1/40\n",
      "26408/26408 [==============================] - 11s - loss: 4.5642 - acc: 0.0526 - val_loss: 3.8094 - val_acc: 0.1071\n",
      "Epoch 2/40\n",
      "26408/26408 [==============================] - 10s - loss: 3.0429 - acc: 0.1893 - val_loss: 2.9008 - val_acc: 0.2319\n",
      "Epoch 3/40\n",
      "26408/26408 [==============================] - 10s - loss: 2.1049 - acc: 0.3804 - val_loss: 1.7825 - val_acc: 0.4775\n",
      "Epoch 4/40\n",
      "26408/26408 [==============================] - 10s - loss: 1.4156 - acc: 0.5802 - val_loss: 1.2680 - val_acc: 0.6257\n",
      "Epoch 5/40\n",
      "26408/26408 [==============================] - 10s - loss: 1.0044 - acc: 0.7371 - val_loss: 0.7410 - val_acc: 0.8410\n",
      "Epoch 6/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.7395 - acc: 0.8260 - val_loss: 0.5572 - val_acc: 0.8780\n",
      "Epoch 7/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.6071 - acc: 0.8635 - val_loss: 0.4789 - val_acc: 0.8947\n",
      "Epoch 8/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.5658 - acc: 0.8784 - val_loss: 0.4187 - val_acc: 0.9139\n",
      "Epoch 9/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.4168 - acc: 0.9081 - val_loss: 0.6040 - val_acc: 0.8461\n",
      "Epoch 10/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.4482 - acc: 0.9053 - val_loss: 0.3190 - val_acc: 0.9343\n",
      "Epoch 11/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.3261 - acc: 0.9310 - val_loss: 0.2839 - val_acc: 0.9422\n",
      "Epoch 12/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.3416 - acc: 0.9322 - val_loss: 0.2865 - val_acc: 0.9418\n",
      "Epoch 13/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.2956 - acc: 0.9387 - val_loss: 0.2352 - val_acc: 0.9521\n",
      "Epoch 14/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.2662 - acc: 0.9449 - val_loss: 0.2164 - val_acc: 0.9555\n",
      "Epoch 15/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.2062 - acc: 0.9550 - val_loss: 1.6023 - val_acc: 0.6550\n",
      "Epoch 16/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.2177 - acc: 0.9555 - val_loss: 0.1823 - val_acc: 0.9619\n",
      "Epoch 17/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.2285 - acc: 0.9542 - val_loss: 0.1761 - val_acc: 0.9633\n",
      "Epoch 18/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.2300 - acc: 0.9556 - val_loss: 0.3346 - val_acc: 0.9155\n",
      "Epoch 19/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.1618 - acc: 0.9654 - val_loss: 0.1705 - val_acc: 0.9650\n",
      "Epoch 20/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.2064 - acc: 0.9602 - val_loss: 0.1610 - val_acc: 0.9683\n",
      "Epoch 21/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.1474 - acc: 0.9686 - val_loss: 0.1770 - val_acc: 0.9609\n",
      "Epoch 22/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.1960 - acc: 0.9622 - val_loss: 0.1450 - val_acc: 0.9671\n",
      "Epoch 23/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.1898 - acc: 0.9611 - val_loss: 0.1503 - val_acc: 0.9673\n",
      "Epoch 24/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.1301 - acc: 0.9722 - val_loss: 0.1463 - val_acc: 0.9682\n",
      "Epoch 25/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.1512 - acc: 0.9673 - val_loss: 0.1459 - val_acc: 0.9673\n",
      "Epoch 26/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.1179 - acc: 0.9735 - val_loss: 0.1322 - val_acc: 0.9705\n",
      "Epoch 27/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.1237 - acc: 0.9730 - val_loss: 0.1294 - val_acc: 0.9733\n",
      "Epoch 28/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.1521 - acc: 0.9679 - val_loss: 0.1254 - val_acc: 0.9720\n",
      "Epoch 29/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.0996 - acc: 0.9765 - val_loss: 0.1384 - val_acc: 0.9708\n",
      "Epoch 30/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.0957 - acc: 0.9763 - val_loss: 0.1226 - val_acc: 0.9728\n",
      "Epoch 31/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.1061 - acc: 0.9747 - val_loss: 0.1509 - val_acc: 0.9659\n",
      "Epoch 32/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.1064 - acc: 0.9758 - val_loss: 0.6451 - val_acc: 0.8871\n",
      "Epoch 33/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.1141 - acc: 0.9732 - val_loss: 0.1085 - val_acc: 0.9741\n",
      "Epoch 34/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.1017 - acc: 0.9763 - val_loss: 0.1154 - val_acc: 0.9732\n",
      "Epoch 35/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.1004 - acc: 0.9769 - val_loss: 0.1052 - val_acc: 0.9752\n",
      "Epoch 36/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.0878 - acc: 0.9784 - val_loss: 0.1027 - val_acc: 0.9756\n",
      "Epoch 37/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.0990 - acc: 0.9769 - val_loss: 0.3118 - val_acc: 0.9345\n",
      "Epoch 38/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.0809 - acc: 0.9789 - val_loss: 0.1057 - val_acc: 0.9742\n",
      "Epoch 39/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.0934 - acc: 0.9777 - val_loss: 0.1015 - val_acc: 0.9754\n",
      "Epoch 40/40\n",
      "26408/26408 [==============================] - 10s - loss: 0.0919 - acc: 0.9763 - val_loss: 0.1031 - val_acc: 0.9753\n"
     ]
    }
   ],
   "source": [
    "model = build_model((X.shape[1], X.shape[2]))\n",
    "history = model.fit(X_train, y_train, validation_data=(X_dev, y_dev), nb_epoch=40, batch_size=256)\n",
    "save_model(model, 'mymodel')\n",
    "embedder = Embedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loaded_model = load_model('output/mymodel')\n",
    "predictor = Predictor(embedder, 'output/mymodel', 'output/intent_names.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sag: Ich möchte mit Kreditkarte bezahlen Sag: Ich möchte mit Visa bezahlen Sag: Ich möchte mit Dollars bezahlen Sag: Ich möchte mit Kreditkarte bezahlen\n"
     ]
    }
   ],
   "source": [
    "print(predictor.predict('i want to pay with by credit card'),\n",
    "predictor.predict('can i buy by post'),\n",
    "predictor.predict('i would pay by dollars'),\n",
    "predictor.predict('can i am a pay with credit card'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "43862/43862 [==============================] - 7s - loss: 0.5454 - acc: 0.9100     \n",
      "Epoch 2/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.5310 - acc: 0.9124     \n",
      "Epoch 3/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.5208 - acc: 0.9139     \n",
      "Epoch 4/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.5124 - acc: 0.9173     \n",
      "Epoch 5/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.5016 - acc: 0.9182     \n",
      "Epoch 6/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.4867 - acc: 0.9234     \n",
      "Epoch 7/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.4827 - acc: 0.9245     \n",
      "Epoch 8/50\n",
      "43862/43862 [==============================] - 7s - loss: 0.4700 - acc: 0.9284     \n",
      "Epoch 9/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.4606 - acc: 0.9308     \n",
      "Epoch 10/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.4558 - acc: 0.9310     \n",
      "Epoch 11/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.4463 - acc: 0.9349     \n",
      "Epoch 12/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.4422 - acc: 0.9353     \n",
      "Epoch 13/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.4288 - acc: 0.9392     \n",
      "Epoch 14/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.4294 - acc: 0.9393     \n",
      "Epoch 15/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.4168 - acc: 0.9436     \n",
      "Epoch 16/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.4165 - acc: 0.9428     \n",
      "Epoch 17/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.4071 - acc: 0.9453     \n",
      "Epoch 18/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.4012 - acc: 0.9467     \n",
      "Epoch 19/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3941 - acc: 0.9486     \n",
      "Epoch 20/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3925 - acc: 0.9494     \n",
      "Epoch 21/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3840 - acc: 0.9503     \n",
      "Epoch 22/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3801 - acc: 0.9521     \n",
      "Epoch 23/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3758 - acc: 0.9544     \n",
      "Epoch 24/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3720 - acc: 0.9538     \n",
      "Epoch 25/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3705 - acc: 0.9538     \n",
      "Epoch 26/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3614 - acc: 0.9571     \n",
      "Epoch 27/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3619 - acc: 0.9568     \n",
      "Epoch 28/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3567 - acc: 0.9580     \n",
      "Epoch 29/50\n",
      "43862/43862 [==============================] - 7s - loss: 0.3530 - acc: 0.9592     \n",
      "Epoch 30/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3490 - acc: 0.9607     \n",
      "Epoch 31/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3470 - acc: 0.9606     \n",
      "Epoch 32/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3442 - acc: 0.9618     \n",
      "Epoch 33/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3411 - acc: 0.9627     \n",
      "Epoch 34/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3373 - acc: 0.9633     \n",
      "Epoch 35/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3386 - acc: 0.9635     \n",
      "Epoch 36/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3304 - acc: 0.9648     \n",
      "Epoch 37/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3317 - acc: 0.9641     \n",
      "Epoch 38/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3294 - acc: 0.9649     \n",
      "Epoch 39/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3257 - acc: 0.9665     \n",
      "Epoch 40/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3253 - acc: 0.9660     \n",
      "Epoch 41/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3255 - acc: 0.9660     \n",
      "Epoch 42/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3204 - acc: 0.9677     \n",
      "Epoch 43/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3185 - acc: 0.9687     \n",
      "Epoch 44/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3164 - acc: 0.9688     \n",
      "Epoch 45/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3175 - acc: 0.9685     \n",
      "Epoch 46/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3150 - acc: 0.9694     \n",
      "Epoch 47/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3135 - acc: 0.9692     \n",
      "Epoch 48/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3116 - acc: 0.9703     \n",
      "Epoch 49/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3086 - acc: 0.9709     \n",
      "Epoch 50/50\n",
      "43862/43862 [==============================] - 6s - loss: 0.3093 - acc: 0.9706     \n"
     ]
    }
   ],
   "source": [
    "model3 = build_model((X.shape[1], X.shape[2]))\n",
    "history = model2.fit(X_train, y_train, nb_epoch=50, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sag: Ich warte auf das bestellte Essen'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = Predictor(embedder, 'output/mymodel3', 'output/intent_names.p')\n",
    "predictor.predict('can i buy by post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sag: Ich möchte nächste Woche abreisen'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict('i want pay by euros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26408 samples, validate on 8794 samples\n",
      "Epoch 1/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0693 - acc: 0.9817 - val_loss: 0.1000 - val_acc: 0.9777\n",
      "Epoch 2/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0721 - acc: 0.9810 - val_loss: 0.0965 - val_acc: 0.9765\n",
      "Epoch 3/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0762 - acc: 0.9808 - val_loss: 0.1070 - val_acc: 0.9784\n",
      "Epoch 4/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0605 - acc: 0.9824 - val_loss: 0.1020 - val_acc: 0.9766\n",
      "Epoch 5/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0927 - acc: 0.9784 - val_loss: 0.1097 - val_acc: 0.9724\n",
      "Epoch 6/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0506 - acc: 0.9854 - val_loss: 0.1097 - val_acc: 0.9752\n",
      "Epoch 7/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0527 - acc: 0.9846 - val_loss: 0.4750 - val_acc: 0.9182\n",
      "Epoch 8/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0732 - acc: 0.9817 - val_loss: 0.0854 - val_acc: 0.9787\n",
      "Epoch 9/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0506 - acc: 0.9849 - val_loss: 0.0936 - val_acc: 0.9796\n",
      "Epoch 10/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0474 - acc: 0.9852 - val_loss: 0.0917 - val_acc: 0.9775\n",
      "Epoch 11/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0710 - acc: 0.9824 - val_loss: 0.0975 - val_acc: 0.9770\n",
      "Epoch 12/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0499 - acc: 0.9850 - val_loss: 0.0927 - val_acc: 0.9776\n",
      "Epoch 13/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0627 - acc: 0.9829 - val_loss: 0.0868 - val_acc: 0.9794\n",
      "Epoch 14/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0435 - acc: 0.9868 - val_loss: 0.0983 - val_acc: 0.9782\n",
      "Epoch 15/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0463 - acc: 0.9859 - val_loss: 0.0887 - val_acc: 0.9777\n",
      "Epoch 16/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0491 - acc: 0.9842 - val_loss: 0.0833 - val_acc: 0.9792\n",
      "Epoch 17/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0441 - acc: 0.9863 - val_loss: 0.0873 - val_acc: 0.9785\n",
      "Epoch 18/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0411 - acc: 0.9868 - val_loss: 0.0919 - val_acc: 0.9778\n",
      "Epoch 19/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0690 - acc: 0.9828 - val_loss: 0.0846 - val_acc: 0.9785\n",
      "Epoch 20/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0430 - acc: 0.9866 - val_loss: 0.1163 - val_acc: 0.9751\n",
      "Epoch 21/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0592 - acc: 0.9842 - val_loss: 0.0833 - val_acc: 0.9799\n",
      "Epoch 22/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0402 - acc: 0.9864 - val_loss: 0.1562 - val_acc: 0.9724\n",
      "Epoch 23/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0393 - acc: 0.9872 - val_loss: 0.0900 - val_acc: 0.9799\n",
      "Epoch 24/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0385 - acc: 0.9864 - val_loss: 0.0862 - val_acc: 0.9798\n",
      "Epoch 25/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0428 - acc: 0.9857 - val_loss: 0.1021 - val_acc: 0.9748\n",
      "Epoch 26/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0435 - acc: 0.9866 - val_loss: 0.0831 - val_acc: 0.9796\n",
      "Epoch 27/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0390 - acc: 0.9867 - val_loss: 0.0823 - val_acc: 0.9809\n",
      "Epoch 28/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0415 - acc: 0.9869 - val_loss: 0.0843 - val_acc: 0.9810\n",
      "Epoch 29/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0404 - acc: 0.9864 - val_loss: 0.0830 - val_acc: 0.9815\n",
      "Epoch 30/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0353 - acc: 0.9873 - val_loss: 0.1007 - val_acc: 0.9791\n",
      "Epoch 31/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0452 - acc: 0.9861 - val_loss: 0.0893 - val_acc: 0.9807\n",
      "Epoch 32/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0373 - acc: 0.9869 - val_loss: 0.0840 - val_acc: 0.9812\n",
      "Epoch 33/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0356 - acc: 0.9871 - val_loss: 0.1065 - val_acc: 0.9771\n",
      "Epoch 34/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0482 - acc: 0.9846 - val_loss: 0.0885 - val_acc: 0.9803\n",
      "Epoch 35/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0370 - acc: 0.9867 - val_loss: 0.0825 - val_acc: 0.9811\n",
      "Epoch 36/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0353 - acc: 0.9870 - val_loss: 0.0923 - val_acc: 0.9814\n",
      "Epoch 37/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0423 - acc: 0.9862 - val_loss: 0.0866 - val_acc: 0.9808\n",
      "Epoch 38/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0321 - acc: 0.9880 - val_loss: 0.0893 - val_acc: 0.9807\n",
      "Epoch 39/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0377 - acc: 0.9873 - val_loss: 0.0941 - val_acc: 0.9806\n",
      "Epoch 40/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0473 - acc: 0.9856 - val_loss: 0.0930 - val_acc: 0.9808\n",
      "Epoch 41/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0461 - acc: 0.9859 - val_loss: 0.0872 - val_acc: 0.9820\n",
      "Epoch 42/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0324 - acc: 0.9875 - val_loss: 0.0861 - val_acc: 0.9799\n",
      "Epoch 43/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0349 - acc: 0.9878 - val_loss: 0.0846 - val_acc: 0.9820\n",
      "Epoch 44/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0336 - acc: 0.9870 - val_loss: 0.0853 - val_acc: 0.9819\n",
      "Epoch 45/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0313 - acc: 0.9880 - val_loss: 0.0943 - val_acc: 0.9802\n",
      "Epoch 46/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0394 - acc: 0.9867 - val_loss: 0.0909 - val_acc: 0.9815\n",
      "Epoch 47/100\n",
      "26408/26408 [==============================] - 9s - loss: 0.0453 - acc: 0.9867 - val_loss: 0.0842 - val_acc: 0.9812\n",
      "Epoch 48/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0513 - acc: 0.9858 - val_loss: 0.0849 - val_acc: 0.9810\n",
      "Epoch 49/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0328 - acc: 0.9879 - val_loss: 0.1017 - val_acc: 0.9792\n",
      "Epoch 50/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0307 - acc: 0.9878 - val_loss: 0.0894 - val_acc: 0.9811\n",
      "Epoch 51/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0321 - acc: 0.9882 - val_loss: 0.0929 - val_acc: 0.9802\n",
      "Epoch 52/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0299 - acc: 0.9883 - val_loss: 0.1115 - val_acc: 0.9796\n",
      "Epoch 53/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0458 - acc: 0.9866 - val_loss: 0.0970 - val_acc: 0.9816\n",
      "Epoch 54/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0464 - acc: 0.9863 - val_loss: 0.0900 - val_acc: 0.9806\n",
      "Epoch 55/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0435 - acc: 0.9867 - val_loss: 0.0936 - val_acc: 0.9811\n",
      "Epoch 56/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0478 - acc: 0.9861 - val_loss: 0.0924 - val_acc: 0.9817\n",
      "Epoch 57/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0313 - acc: 0.9883 - val_loss: 0.0909 - val_acc: 0.9810\n",
      "Epoch 58/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0337 - acc: 0.9878 - val_loss: 0.0914 - val_acc: 0.9814\n",
      "Epoch 59/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0285 - acc: 0.9886 - val_loss: 0.0986 - val_acc: 0.9818\n",
      "Epoch 60/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0294 - acc: 0.9888 - val_loss: 0.1078 - val_acc: 0.9804\n",
      "Epoch 61/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0386 - acc: 0.9872 - val_loss: 0.0881 - val_acc: 0.9815\n",
      "Epoch 62/100\n",
      "26408/26408 [==============================] - 9s - loss: 0.0286 - acc: 0.9892 - val_loss: 0.0920 - val_acc: 0.9811\n",
      "Epoch 63/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0293 - acc: 0.9886 - val_loss: 0.0965 - val_acc: 0.9803\n",
      "Epoch 64/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0407 - acc: 0.9862 - val_loss: 0.0965 - val_acc: 0.9812\n",
      "Epoch 65/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0281 - acc: 0.9886 - val_loss: 0.0982 - val_acc: 0.9804\n",
      "Epoch 66/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0287 - acc: 0.9885 - val_loss: 0.0988 - val_acc: 0.9804\n",
      "Epoch 67/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0301 - acc: 0.9880 - val_loss: 0.1027 - val_acc: 0.9807\n",
      "Epoch 68/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0308 - acc: 0.9885 - val_loss: 0.1049 - val_acc: 0.9807\n",
      "Epoch 69/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0278 - acc: 0.9885 - val_loss: 0.1003 - val_acc: 0.9810\n",
      "Epoch 70/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0288 - acc: 0.9885 - val_loss: 0.0940 - val_acc: 0.9800\n",
      "Epoch 71/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0310 - acc: 0.9887 - val_loss: 0.0988 - val_acc: 0.9801\n",
      "Epoch 72/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0292 - acc: 0.9886 - val_loss: 0.1075 - val_acc: 0.9791\n",
      "Epoch 73/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0304 - acc: 0.9888 - val_loss: 0.1099 - val_acc: 0.9799\n",
      "Epoch 74/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0335 - acc: 0.9883 - val_loss: 0.0916 - val_acc: 0.9814\n",
      "Epoch 75/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0276 - acc: 0.9892 - val_loss: 0.1011 - val_acc: 0.9816\n",
      "Epoch 76/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0279 - acc: 0.9889 - val_loss: 0.0999 - val_acc: 0.9807\n",
      "Epoch 77/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0378 - acc: 0.9875 - val_loss: 0.1022 - val_acc: 0.9806\n",
      "Epoch 78/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0315 - acc: 0.9888 - val_loss: 0.0957 - val_acc: 0.9820\n",
      "Epoch 79/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0488 - acc: 0.9864 - val_loss: 0.0985 - val_acc: 0.9810\n",
      "Epoch 80/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0265 - acc: 0.9894 - val_loss: 0.1058 - val_acc: 0.9812\n",
      "Epoch 81/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0361 - acc: 0.9880 - val_loss: 0.0979 - val_acc: 0.9817\n",
      "Epoch 82/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0264 - acc: 0.9894 - val_loss: 0.0945 - val_acc: 0.9807\n",
      "Epoch 83/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0271 - acc: 0.9890 - val_loss: 0.0981 - val_acc: 0.9817\n",
      "Epoch 84/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0270 - acc: 0.9891 - val_loss: 0.0961 - val_acc: 0.9812\n",
      "Epoch 85/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0285 - acc: 0.9891 - val_loss: 0.1049 - val_acc: 0.9817\n",
      "Epoch 86/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0366 - acc: 0.9884 - val_loss: 0.1020 - val_acc: 0.9824\n",
      "Epoch 87/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0337 - acc: 0.9881 - val_loss: 0.0986 - val_acc: 0.9819\n",
      "Epoch 88/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0262 - acc: 0.9893 - val_loss: 0.0943 - val_acc: 0.9821\n",
      "Epoch 89/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0555 - acc: 0.9860 - val_loss: 0.1084 - val_acc: 0.9800\n",
      "Epoch 90/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0254 - acc: 0.9895 - val_loss: 0.1024 - val_acc: 0.9812\n",
      "Epoch 91/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0312 - acc: 0.9886 - val_loss: 0.0996 - val_acc: 0.9820\n",
      "Epoch 92/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0267 - acc: 0.9891 - val_loss: 0.1032 - val_acc: 0.9817\n",
      "Epoch 93/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0329 - acc: 0.9886 - val_loss: 0.1007 - val_acc: 0.9821\n",
      "Epoch 94/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0269 - acc: 0.9892 - val_loss: 0.3527 - val_acc: 0.9519\n",
      "Epoch 95/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0334 - acc: 0.9885 - val_loss: 0.0987 - val_acc: 0.9814\n",
      "Epoch 96/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0278 - acc: 0.9894 - val_loss: 0.0998 - val_acc: 0.9817\n",
      "Epoch 97/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0297 - acc: 0.9889 - val_loss: 0.0968 - val_acc: 0.9814\n",
      "Epoch 98/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0287 - acc: 0.9888 - val_loss: 0.0992 - val_acc: 0.9819\n",
      "Epoch 99/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0452 - acc: 0.9873 - val_loss: 0.1157 - val_acc: 0.9798\n",
      "Epoch 100/100\n",
      "26408/26408 [==============================] - 10s - loss: 0.0250 - acc: 0.9896 - val_loss: 0.0964 - val_acc: 0.9826\n",
      "Loading spacy...\n",
      "...done\n",
      "Sag: Ich möchte mit Kreditkarte bezahlen Frag: ein Ticket für Oliver Twist Sag: Ich möchte mit Dollars bezahlen Sag: Ich möchte mit Kreditkarte bezahlen\n"
     ]
    }
   ],
   "source": [
    "modelF = build_model((X.shape[1], X.shape[2]))\n",
    "history = model.fit(X_train, y_train, validation_data=(X_dev, y_dev), nb_epoch=100, batch_size=256)\n",
    "def save_model(model):\n",
    "    model.save('output/mymodelF')\n",
    "\n",
    "save_model(model)\n",
    "pickle.dump(intent_names, open(\"output/intent_names.p\", \"wb\"))\n",
    "loaded_model = load_model('output/mymodelF')\n",
    "loaded_intent_names = pickle.load(open(\"output/intent_names.p\", \"rb\"))\n",
    "\n",
    "\n",
    "def predict(model, text):\n",
    "    embedding = embedder.embed(text)\n",
    "    return model.predict(np.array([embedding]))\n",
    "\n",
    "\n",
    "def translate(prediction, intent_names):\n",
    "    return intent_names[np.argmax(prediction)]\n",
    "\n",
    "\n",
    "def suggest(text):\n",
    "    prediction = predict(loaded_model, text)\n",
    "    return translate(prediction, loaded_intent_names)\n",
    "\n",
    "embedder = Embedder()\n",
    "predictor = Predictor(embedder, 'output/mymodelF', 'output/intent_names.p')\n",
    "print(predictor.predict('i want to pay with by credit card'),\n",
    "predictor.predict('can i buy by post'),\n",
    "predictor.predict('i would pay by dollars'),\n",
    "predictor.predict('can i am a pay with credit card'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Model on ST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kaldi = open('kaldi', 'r')\n",
    "out = open('out', 'a')\n",
    "for line in kaldi:\n",
    "    out.write(predictor.predict(line) + '\\n')\n",
    "    \n",
    "kaldi.close()\n",
    "out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
